# Change working directory
setwd("~/Documents/R_Project")
# Get the file
data <- read.csv("final_data.csv")
data # read successful
library(tidyverse)
library(ggplot2)
library(caret)
library(car)
library(neuralnet)
library(Metrics)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
install.packages("GGalley")
library(GGally)
data <- data %>%
select(-serial, -model_name, -release_date, -lowest_price, -highest_price)
# I do not think model name and release data has relation
data
print(cor(data[,2:7]))
print(cor(data[,1:7]))
print(cor(data[,1]))
print(cor(data[,1:7]))
ggplot(data, aes(x = popularity , y = best_price)) + geom_point()+stat_smooth(method=lm)
# Get the file
data <- read.csv("final_data.csv")
data <- data %>%
select(-os, -serial, -model_name, -release_date, -lowest_price, -highest_price)
print(cor(data[,1:6]))
ggplot(data, aes(x = popularity , y = best_price)) + geom_point()+stat_smooth(method=lm)
corMatrix<-round(cor(data),2)
corMatrix
# Get the file
data <- read.csv("final_data.csv")
data # read successful
data <- data %>%
select( -serial, -model_name, -release_date, -lowest_price, -highest_price)
# I do not think model name and release data has relation
data
print(cor(data[,1:7]))
ggplot(data, aes(x = popularity , y = best_price)) + geom_point()+stat_smooth(method=lm)
corMatrix<-round(cor(data),2)
corMatrix
# finding correlation
findCorrelation(corMatrix, cutoff = 0.7, names = TRUE)
library(caret)
install.packages('stringi')
# install.packages('stringi')
library(caret)
library(Metrics)
# install.packages('stringi')
library(caret)
# finding correlation
findCorrelation(corMatrix, cutoff = 0.7, names = TRUE)
# finding correlation
findCorrelation(corMatrix, cutoff = 0.6, names = TRUE)
# finding correlation
findCorrelation(corMatrix, cutoff = 0.5, names = TRUE)
# finding correlation
findCorrelation(corMatrix, cutoff = 0.4, names = TRUE)
# finding correlation
findCorrelation(corMatrix, cutoff = 0.7, names = TRUE)
# regression
reg<-lm(best_price~os+popularity+sellers_amount+screen_size+memory_size+battery_size,data)
summary(reg)
vif(reg)
# libraries
library(tidyverse)
library(ggplot2)
# install.packages('stringi')
library(caret)
library(car)
library(neuralnet)
library(Metrics)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
# install.packages("GGalley")
library(GGally)
vif(reg)
reg<-lm(best_price~os+popularity+sellers_amount+memory_size+battery_size,data)
summary(reg)
vif(reg)
# declare the function
scale <- function(x){(x - min(x)) / (max(x) - min(x))}
data <- data %>%
mutate_all(scale)
set.seed(12345)
train_data <- sample_frac(data, replace = FALSE, size = 0.80)
test_data <- anti_join(data, train_data)
set.seed(12321)
NN1 <- neuralnet(best_price~os+popularity+sellers_amount+memory_size+battery_size, data = data)
data <- data %>%
select( -serial, -model_name, -release_date, -lowest_price, -highest_price)
# Get the file
data <- read.csv("final_data.csv")
data # read successful
data <- data %>%
select( -serial, -model_name, -release_date, -lowest_price, -highest_price)
# I do not think model name and release data has relation
data
data <- data %>%
mutate_all(scale)
set.seed(12345)
train_data <- sample_frac(data, replace = FALSE, size = 0.80)
test_data <- anti_join(data, train_data)
set.seed(12321)
NN1 <- neuralnet(best_price~os+popularity+sellers_amount+memory_size+battery_size, data = data)
NN1 <- neuralnet(best_price~popularity+sellers_amount+memory_size+battery_size, data = data)
NN1 <- neuralnet(best_price~os+popularity+sellers_amount+battery_size, data = data)
NN1 <- neuralnet(best_price~os+popularity+sellers_amount+memory_size+battery_size, data = train_data)
NN1 <- neuralnet(best_price~os+popularity+sellers_amount+memory_size, data = data)
plot(NN1, rep = 'best')
